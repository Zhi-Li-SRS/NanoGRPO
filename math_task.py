import re
from pathlib import Path
from typing import Any, Dict, List, Optional
import pandas as pd
from torch.utils.data import Dataset

from data_types import MiniBatch
from tokenizer import Tokenizer


# SYSTEM_MESSAGE define the basic behavior of the assistant
SYSTEM_MESSAGE = (
    "You are a helpful assistant. You first think about the reasoning process "
    "in your mind and then provide the user with the answer."
)

# USER_TEMPLATE define the template of the user's request
USER_TEMPLATE = (
    "Using the numbers {numbers}, create an equation that equals {target}. "
    "You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. "
    "Show your work in <think> </think> tags. "
    "And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>."
)

# RESPONSE_PROMPT
RESPONSE_PROMPT = "Let me solve this step by step.\n<think>"


# CountdownTasksDataset class is used to prepare the dataset for the countdown task, which is used to train the model.
class CountdownTasksDataset(Dataset):
    """
    CountdownTasksDataset class is used to prepare the dataset for the countdown task, which is used to train the model.

    """
    def __init__(
        self,
        tokenizer: Tokenizer,
        data_path: str,
        split: str = "train",
        test_size: int = 100,
    ):
        """
        Args:
            tokenizer (Tokenizer): the tokenizer used to convert the text to the input format accepted by the model
            data_path (str): the path to the dataset
            split (str): train or test
            test_size (int): the size of the test set
        """
        data = pd.read_parquet(Path(data_path) / "data")

        self.data = (
            data.iloc[:-test_size] if split == "train" else data.iloc[-test_size:]
        )
        self.tokenizer = tokenizer

    def __len__(self):
        """
        return the length of the dataset
        """
        return len(self.data)

    def __getitem__(self, idx):
        """
        get the item at the given index

        Args:
            idx (int): the index of the item

        Returns:
            dict: the encoded item, including the original data and the encoded prefix
        """
        item = self.data.iloc[idx].to_dict()
        item.update(self.encode_prefix(item["numbers"], item["target"]))
        return item

    def encode_prefix(self, numbers: List[int], target: int):
        """
        encode the prefix

        Args:
            numbers (List[int]): a list of numbers
            target (int): the target value

        Returns:
            dict: the encoded item, including the original data and the encoded prefix
        """
        user_message = USER_TEMPLATE.format(numbers=numbers, target=target)

        prefix = self.tokenizer.encode_chat_with_response_prompt(
            [
                {"role": "system", "content": SYSTEM_MESSAGE},
                {"role": "user", "content": user_message},
            ],
            RESPONSE_PROMPT,
        )

        # Tokenize the prefix text to generate a list of tokens and a list of token IDs.
        tokens = self.tokenizer.tokenize(prefix)
        return {
            "prefix": prefix,
            "prefix_tokens": tokens.tokens,
            "prefix_token_ids": tokens.ids,
        }

    @staticmethod
    def collate_fn(batch: List[Dict[str, Any]]) -> MiniBatch:
        """
        Collates a batch of samples into a single batch.

        Args:
            batch (List[Dict[str, Any]]): A list of samples, where each sample is a dictionary.

        Returns:
            MiniBatch: The collated batch object, containing numbers, target values, prefix texts, token lists, and token ID lists.
        """
        # Extract the list of numbers, list of target values, list of prefix texts, list of tokens, and list of token IDs from the batch.
        numbers = [item["nums"] for item in batch]
        target = [item["target"] for item in batch]
        prefix = [item["prefix"] for item in batch]
        prefix_tokens = [item["prefix_tokens"] for item in batch]
        prefix_token_ids = [item["prefix_token_ids"] for item in batch]
        # Return a MiniBatch object containing the collated data.
        return MiniBatch(
            numbers=numbers,
            target=target,
            prefix=prefix,
            prefix_tokens=prefix_tokens,
            prefix_token_ids=prefix_token_ids,
        )


def format_reward_function(response: str, end_token: Optional[str] = None) -> float:
    """
    Check if the response conforms to the format
    <think>...</think><answer>...</answer>

    Args:
        response (str): The response text generated by the AI.
        end_token (Optional[str]): An optional end token. If provided and the response ends with this token, it will be removed before matching.

    Returns:
        float: Returns 1.0 if the response fully conforms to the format; otherwise, returns a corresponding reward score based on partial matches.
    """

    # If an end_token is provided and the response ends with it, remove the end_token
    if end_token and response.endswith(end_token):
        response = response[: -len(end_token)]

   
    think_regex = r"<think>.*?</think>"
 
    answer_regex = r"<answer>.*?</answer>"
    
    full_format_regex = r"^<think>.*?</think>\n<answer>.*?</answer>$"

    # Use regex to search for the <think>...</think> part, re.DOTALL makes . match all characters including newlines
    think_match = re.search(think_regex, response, re.DOTALL)
   
    answer_match = re.search(answer_regex, response, re.DOTALL)
    
    full_format_match = re.match(full_format_regex, response, re.DOTALL)

    # If the entire response matches the format completely, return the maximum reward of 1.0
    if full_format_match:
        return 1.0

    reward = 0.0
   
    if think_match:
        reward += 0.1

    if answer_match:
        reward += 0.5
    
    return reward


def answer_reward_function(
    response: str, numbers: List[int] = None, target: int = None
) -> float:
    """
    Checks if the answer uses all the provided numbers exactly once and verifies if the answer equals the target value.

    Args:
        response (str): The response text generated by the AI.
        numbers (List[int], optional): A list of numbers that should be included in the answer, with each number used only once.
        target (int, optional): The target value that the answer should evaluate to.

    Returns:
        float: Returns 1.0 if the answer meets all the conditions; otherwise, returns 0.0.
    """

    
    answer_regex = r"<answer>(.*?)</answer>"
    
    answer_match = re.search(answer_regex, response, re.DOTALL)
   
    if not answer_match:
        return 0.0
  
    answer_content = answer_match.group(1)
    if not answer_content:
        return 0.0

    # Define the allowed character set (numbers, plus, minus, multiply, divide, parentheses, and spaces)
    allowed_chars = r"^[0-9+\-*/() ]+$"
    if not re.match(allowed_chars, answer_content):
        return 0.0

    used_numbers = [int(n) for n in re.findall(r"\d+", answer_content)]
    if sorted(used_numbers) != sorted(numbers):
        return 0.0

    try:
        # Use a restricted global namespace to evaluate the expression to prevent the execution of malicious code
        result = eval(answer_content, {"__builtins__": None}, {})
        if abs(float(result) - float(target)) < 1e-5:
            return 1.0
    except:
        pass

    return 0.0


def reward_function(
    response: str,
    numbers: List[int] = None,
    target: int = None,
    end_token: str = None,
) -> Dict[str, Any]:
    """
    Reward function for the countdown task.

    Total reward = 0.1 * format reward + answer reward

    Args:
        response (str): The response text generated by the AI.
        numbers (List[int], optional): A list of numbers that should be included in the answer, with each number used only once.
        target (int, optional): The target value that the answer should evaluate to.
        end_token (str, optional): An optional end token to identify the end of the response.

    Returns:
        Dict[str, Any]: A dictionary containing the total reward and detailed reward information.
    """

    format_reward = format_reward_function("<think>" + response, end_token)
    answer_reward = answer_reward_function(response, numbers, target)
    return {
        "reward": format_reward * 0.1 + answer_reward,
        "reward_info": {
            "format_reward": format_reward,
            "answer_reward": answer_reward,
        },
    }
